{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model\n",
    "In this section of our project we are trying to estimate the number of animal of a certain specie basing ourselves on observations of this specie. We are specifically focusing on deer but if the method reveals to be efficient, we can generalize our results to any specie.\n",
    "\n",
    "It is important to note that by looking at counts from different years, we found that there are more data points as years go on. We have theorized that this may be due to scientists using the gbif website to record more as they may have found this site to be more useful, and also due to the fact that it has become much more easier in the past ten years to record data that it was in the nineties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.misc import *\n",
    "from scipy.sparse import *\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.gbif.org/occurrence/search?TAXON_KEY=359&YEAR=2014#\n",
    "# This is data for all Mammals in 2014 across the whole planet\n",
    "mammals = pandas.read_csv('/Users/macuser/Desktop/Mammalia_US_to2015.csv', sep='\\t', usecols=['year','species'], nrows=500000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Procyon lotor</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zalophus californianus</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vulpes vulpes</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Odocoileus hemionus</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lepus californicus</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  species  year\n",
       "0           Procyon lotor  2014\n",
       "1  Zalophus californianus  2014\n",
       "2           Vulpes vulpes  2014\n",
       "3     Odocoileus hemionus  2014\n",
       "4      Lepus californicus  2014"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gbifid', 'datasetkey', 'occurrenceid', 'kingdom', 'phylum',\n",
       "       'class', 'order', 'family', 'genus', 'species',\n",
       "       'infraspecificepithet', 'taxonrank', 'scientificname',\n",
       "       'countrycode', 'locality', 'publishingorgkey', 'decimallatitude',\n",
       "       'decimallongitude', 'coordinateuncertaintyinmeters',\n",
       "       'coordinateprecision', 'elevation', 'elevationaccuracy', 'depth',\n",
       "       'depthaccuracy', 'eventdate', 'day', 'month', 'year', 'taxonkey',\n",
       "       'specieskey', 'basisofrecord', 'institutioncode', 'collectioncode',\n",
       "       'catalognumber', 'recordnumber', 'identifiedby', 'rights',\n",
       "       'rightsholder', 'recordedby', 'typestatus', 'establishmentmeans',\n",
       "       'lastinterpreted', 'mediatype', 'issue'], dtype=object)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deer=pd.read_csv('/Users/macuser/Desktop/Jupyter/AM207/AM207Project/Data/Deer_2015.csv', sep='\\t')\n",
    "deer.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a subset data frame that just contains the columns that we need\n",
    "occurences_mammals = mammals['year'].value_counts()\n",
    "occurences = deer[deer.year>=1991]\n",
    "occurences_deer=occurences['year'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015    1285\n",
      "2014     985\n",
      "2013     786\n",
      "2012     543\n",
      "2003     337\n",
      "2011     289\n",
      "1999     264\n",
      "2009     251\n",
      "2010     237\n",
      "1995     227\n",
      "1998     217\n",
      "1991     198\n",
      "2007     173\n",
      "1992     168\n",
      "2006     167\n",
      "2004     121\n",
      "1994     119\n",
      "1996     104\n",
      "2002      98\n",
      "2001      87\n",
      "2008      84\n",
      "2000      71\n",
      "1993      70\n",
      "1997      61\n",
      "2005      54\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print occurences_deer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86614173,  0.54165592,  0.24145424,  0.30242192,  0.73857166,\n",
       "        0.29956505,  0.25768841,  0.78492368,  1.08499096,  0.32609195,\n",
       "        0.38368247,  0.37480399,  1.55751722,  0.60755172,  0.33047736,\n",
       "        1.16750559,  1.37892555,  0.90177134,  2.17391304,  2.39393939,\n",
       "        2.46692275,  6.0166205 ,  7.25226056,  8.64110887])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deer_obs=[198.,168.,70.,119.,227.,104.,61.,217.,264.,71.,87.,98.,337.,121.,54.,167.,173.,84.,251.,237.,289.,543.,786.,\\\n",
    "          985.]\n",
    "mammal_obs=[22860,31016,28991,39349,30735, 34717,23672,27646,24332,21773,22675,26147,21637,19916,16340,14304,12546,\\\n",
    "           9315,11546,9900,11715,9025,10838,11399]\n",
    "\n",
    "# What percentages are the deer observations out of all mammals\n",
    "percentage=np.divide(deer_obs,mammal_obs)*100\n",
    "percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of deer observations increases in the past few years (since 2005, although the actual number of deer is decreasing) we normalize the data counts using the average number of mammals observation over the years.\n",
    "Indeed, we assume the number of observed mammal should be the same over the years and use that ratio (average observation of mammals divided by observations on that year) as a factor to normalize the observations of deer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89748104,  0.66147848,  0.70768227,  0.52139614,  0.66752616,\n",
       "        0.59096168,  0.86669553,  0.74211158,  0.84318661,  0.94228708,\n",
       "        0.90480338,  0.78465662,  0.94820986,  1.03014745,  1.25559466,\n",
       "        1.43431325,  1.63529545,  2.20251387,  1.77692852,  2.07236532,\n",
       "        1.75129464,  2.27328717,  1.89300763,  1.79984355])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize by the relative number of observations\n",
    "average_norm=np.divide(float(np.sum(mammal_obs))/len(mammal_obs),mammal_obs)\n",
    "average_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  177.70124672,   111.12838535,    49.53775884,    62.04614052,\n",
       "         151.52843935,    61.46001479,    52.86842754,   161.03821228,\n",
       "         222.60126582,    66.90238292,    78.71789416,    76.89634885,\n",
       "         319.54672167,   124.64784177,    67.80211138,   239.53031203,\n",
       "         282.90611217,   185.01116479,   446.00905797,   491.15058081,\n",
       "         506.12414995,  1234.39493075,  1487.9039952 ,  1772.84590023])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deer represent approximately in percentages 1.7121 % of the mammals observations\n",
    "norm_obs=np.multiply(average_norm,deer_obs)\n",
    "norm_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1991.,  1992.,  1993.,  1994.,  1995.,  1996.,  1997.,  1998.,\n",
       "        1999.,  2000.,  2001.,  2002.,  2003.,  2004.,  2005.,  2006.,\n",
       "        2007.,  2008.,  2009.,  2010.,  2011.,  2012.,  2013.,  2014.])"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years=np.linspace(1991,2014,24)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Actual estimated deer number US: http://www.deerfriendly.com/decline-of-deer-populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In Millions\n",
    "actual_deer=[35.5, 35.75, 36., 36.2, 36.5, 36.8, 37.1, 37.4, 37.7, 38.1, 37.85, 37.5, 37.1, 36.8, 36.4, 36.1, 35.75,\\\n",
    "             35.4, 35., 34.6, 34.2, 33.8, 33.5, 33.2]\n",
    "act_deer=np.multiply(actual_deer,10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.00566892   3.1084863    1.37604886   1.71398178   4.15146409\n",
      "   1.6701091    1.425025     4.30583455   5.90454286   1.75596806\n",
      "   2.079733     2.0505693    8.61311918   3.38716961   1.86269537\n",
      "   6.6351887    7.91345768   5.22630409  12.74311594  14.19510349\n",
      "  14.79895175  36.52056008  44.41504463  53.3989729 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.,   4.,   7.,  10.,  13.,  16.,  37.,  46.,  55.])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio=np.divide(norm_obs,actual_deer)  \n",
    "# This has to be divided by 10^6 but for simplicity purposes, I will keep it this way\n",
    "print ratio\n",
    "discretized_r=np.linspace(1,55,19)\n",
    "\n",
    "discrete_ratio=np.zeros(len(actual_deer))\n",
    "for i in range(len(ratio)):\n",
    "    for j in range(len(discretized_r)-1):\n",
    "        if ratio[i]>discretized_r[j] and ratio[i]<discretized_r[j]+0.5:\n",
    "            discrete_ratio[i]=discretized_r[j]\n",
    "        elif ratio[i]<discretized_r[j+1] and ratio[i]>=discretized_r[j]+0.5:\n",
    "            discrete_ratio[i]=discretized_r[j+1]\n",
    "        elif ratio[i]==discretized_r[j]:\n",
    "            discrete_ratio[i]=discretized_r[j]\n",
    "discrete_ratio\n",
    "obs_len=len(np.unique(discrete_ratio))\n",
    "obs_states=(np.unique(discrete_ratio))\n",
    "obs_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For discretization\n",
    "discrete_states=np.linspace(30,40,41)\n",
    "\n",
    "discrete=np.zeros(len(actual_deer))\n",
    "for i in range(len(actual_deer)):\n",
    "    for j in range(len(discrete_states)-1):\n",
    "        if actual_deer[i]>discrete_states[j] and actual_deer[i]<discrete_states[j+1]:\n",
    "            discrete[i]=discrete_states[j+1]\n",
    "        elif actual_deer[i]==discrete_states[j]:\n",
    "            discrete[i]=discrete_states[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Deer number actual California (up to 2013 only) http://www.deerfriendly.com/deer/california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cali_estimated=[850000,800000,700000,670000,690000,580000,580000,580000,550000,500000,500000,680000,550000,500000,\\\n",
    "                     600000,405000,420000,500000,500000,490000,460000,480000,480000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_deer (Mi)</th>\n",
       "      <th>Comparison_average</th>\n",
       "      <th>Deer_obs</th>\n",
       "      <th>Discrete Ratio</th>\n",
       "      <th>Discretized_actual</th>\n",
       "      <th>Mammals_obs</th>\n",
       "      <th>Normalized_obs</th>\n",
       "      <th>Percentage_deer</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.50</td>\n",
       "      <td>0.897481</td>\n",
       "      <td>198</td>\n",
       "      <td>7</td>\n",
       "      <td>35.50</td>\n",
       "      <td>22860</td>\n",
       "      <td>177.701247</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>5.005669</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.75</td>\n",
       "      <td>0.661478</td>\n",
       "      <td>168</td>\n",
       "      <td>4</td>\n",
       "      <td>35.75</td>\n",
       "      <td>31016</td>\n",
       "      <td>111.128385</td>\n",
       "      <td>0.541656</td>\n",
       "      <td>3.108486</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.00</td>\n",
       "      <td>0.707682</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>36.00</td>\n",
       "      <td>28991</td>\n",
       "      <td>49.537759</td>\n",
       "      <td>0.241454</td>\n",
       "      <td>1.376049</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.20</td>\n",
       "      <td>0.521396</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>36.25</td>\n",
       "      <td>39349</td>\n",
       "      <td>62.046141</td>\n",
       "      <td>0.302422</td>\n",
       "      <td>1.713982</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.50</td>\n",
       "      <td>0.667526</td>\n",
       "      <td>227</td>\n",
       "      <td>4</td>\n",
       "      <td>36.50</td>\n",
       "      <td>30735</td>\n",
       "      <td>151.528439</td>\n",
       "      <td>0.738572</td>\n",
       "      <td>4.151464</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.80</td>\n",
       "      <td>0.590962</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>37.00</td>\n",
       "      <td>34717</td>\n",
       "      <td>61.460015</td>\n",
       "      <td>0.299565</td>\n",
       "      <td>1.670109</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37.10</td>\n",
       "      <td>0.866696</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>37.25</td>\n",
       "      <td>23672</td>\n",
       "      <td>52.868428</td>\n",
       "      <td>0.257688</td>\n",
       "      <td>1.425025</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.40</td>\n",
       "      <td>0.742112</td>\n",
       "      <td>217</td>\n",
       "      <td>4</td>\n",
       "      <td>37.50</td>\n",
       "      <td>27646</td>\n",
       "      <td>161.038212</td>\n",
       "      <td>0.784924</td>\n",
       "      <td>4.305835</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.70</td>\n",
       "      <td>0.843187</td>\n",
       "      <td>264</td>\n",
       "      <td>7</td>\n",
       "      <td>37.75</td>\n",
       "      <td>24332</td>\n",
       "      <td>222.601266</td>\n",
       "      <td>1.084991</td>\n",
       "      <td>5.904543</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.10</td>\n",
       "      <td>0.942287</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>38.25</td>\n",
       "      <td>21773</td>\n",
       "      <td>66.902383</td>\n",
       "      <td>0.326092</td>\n",
       "      <td>1.755968</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37.85</td>\n",
       "      <td>0.904803</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>38.00</td>\n",
       "      <td>22675</td>\n",
       "      <td>78.717894</td>\n",
       "      <td>0.383682</td>\n",
       "      <td>2.079733</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.50</td>\n",
       "      <td>0.784657</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>37.50</td>\n",
       "      <td>26147</td>\n",
       "      <td>76.896349</td>\n",
       "      <td>0.374804</td>\n",
       "      <td>2.050569</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37.10</td>\n",
       "      <td>0.948210</td>\n",
       "      <td>337</td>\n",
       "      <td>10</td>\n",
       "      <td>37.25</td>\n",
       "      <td>21637</td>\n",
       "      <td>319.546722</td>\n",
       "      <td>1.557517</td>\n",
       "      <td>8.613119</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.80</td>\n",
       "      <td>1.030147</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>37.00</td>\n",
       "      <td>19916</td>\n",
       "      <td>124.647842</td>\n",
       "      <td>0.607552</td>\n",
       "      <td>3.387170</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.40</td>\n",
       "      <td>1.255595</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>36.50</td>\n",
       "      <td>16340</td>\n",
       "      <td>67.802111</td>\n",
       "      <td>0.330477</td>\n",
       "      <td>1.862695</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.10</td>\n",
       "      <td>1.434313</td>\n",
       "      <td>167</td>\n",
       "      <td>7</td>\n",
       "      <td>36.25</td>\n",
       "      <td>14304</td>\n",
       "      <td>239.530312</td>\n",
       "      <td>1.167506</td>\n",
       "      <td>6.635189</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35.75</td>\n",
       "      <td>1.635295</td>\n",
       "      <td>173</td>\n",
       "      <td>10</td>\n",
       "      <td>35.75</td>\n",
       "      <td>12546</td>\n",
       "      <td>282.906112</td>\n",
       "      <td>1.378926</td>\n",
       "      <td>7.913458</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35.40</td>\n",
       "      <td>2.202514</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>35.50</td>\n",
       "      <td>9315</td>\n",
       "      <td>185.011165</td>\n",
       "      <td>0.901771</td>\n",
       "      <td>5.226304</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35.00</td>\n",
       "      <td>1.776929</td>\n",
       "      <td>251</td>\n",
       "      <td>13</td>\n",
       "      <td>35.00</td>\n",
       "      <td>11546</td>\n",
       "      <td>446.009058</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>12.743116</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34.60</td>\n",
       "      <td>2.072365</td>\n",
       "      <td>237</td>\n",
       "      <td>16</td>\n",
       "      <td>34.75</td>\n",
       "      <td>9900</td>\n",
       "      <td>491.150581</td>\n",
       "      <td>2.393939</td>\n",
       "      <td>14.195103</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>34.20</td>\n",
       "      <td>1.751295</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>34.25</td>\n",
       "      <td>11715</td>\n",
       "      <td>506.124150</td>\n",
       "      <td>2.466923</td>\n",
       "      <td>14.798952</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33.80</td>\n",
       "      <td>2.273287</td>\n",
       "      <td>543</td>\n",
       "      <td>37</td>\n",
       "      <td>34.00</td>\n",
       "      <td>9025</td>\n",
       "      <td>1234.394931</td>\n",
       "      <td>6.016620</td>\n",
       "      <td>36.520560</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33.50</td>\n",
       "      <td>1.893008</td>\n",
       "      <td>786</td>\n",
       "      <td>46</td>\n",
       "      <td>33.50</td>\n",
       "      <td>10838</td>\n",
       "      <td>1487.903995</td>\n",
       "      <td>7.252261</td>\n",
       "      <td>44.415045</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33.20</td>\n",
       "      <td>1.799844</td>\n",
       "      <td>985</td>\n",
       "      <td>55</td>\n",
       "      <td>33.25</td>\n",
       "      <td>11399</td>\n",
       "      <td>1772.845900</td>\n",
       "      <td>8.641109</td>\n",
       "      <td>53.398973</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual_deer (Mi)  Comparison_average  Deer_obs  Discrete Ratio  \\\n",
       "0              35.50            0.897481       198               7   \n",
       "1              35.75            0.661478       168               4   \n",
       "2              36.00            0.707682        70               1   \n",
       "3              36.20            0.521396       119               4   \n",
       "4              36.50            0.667526       227               4   \n",
       "5              36.80            0.590962       104               4   \n",
       "6              37.10            0.866696        61               1   \n",
       "7              37.40            0.742112       217               4   \n",
       "8              37.70            0.843187       264               7   \n",
       "9              38.10            0.942287        71               4   \n",
       "10             37.85            0.904803        87               4   \n",
       "11             37.50            0.784657        98               4   \n",
       "12             37.10            0.948210       337              10   \n",
       "13             36.80            1.030147       121               4   \n",
       "14             36.40            1.255595        54               4   \n",
       "15             36.10            1.434313       167               7   \n",
       "16             35.75            1.635295       173              10   \n",
       "17             35.40            2.202514        84               7   \n",
       "18             35.00            1.776929       251              13   \n",
       "19             34.60            2.072365       237              16   \n",
       "20             34.20            1.751295       289              16   \n",
       "21             33.80            2.273287       543              37   \n",
       "22             33.50            1.893008       786              46   \n",
       "23             33.20            1.799844       985              55   \n",
       "\n",
       "    Discretized_actual  Mammals_obs  Normalized_obs  Percentage_deer  \\\n",
       "0                35.50        22860      177.701247         0.866142   \n",
       "1                35.75        31016      111.128385         0.541656   \n",
       "2                36.00        28991       49.537759         0.241454   \n",
       "3                36.25        39349       62.046141         0.302422   \n",
       "4                36.50        30735      151.528439         0.738572   \n",
       "5                37.00        34717       61.460015         0.299565   \n",
       "6                37.25        23672       52.868428         0.257688   \n",
       "7                37.50        27646      161.038212         0.784924   \n",
       "8                37.75        24332      222.601266         1.084991   \n",
       "9                38.25        21773       66.902383         0.326092   \n",
       "10               38.00        22675       78.717894         0.383682   \n",
       "11               37.50        26147       76.896349         0.374804   \n",
       "12               37.25        21637      319.546722         1.557517   \n",
       "13               37.00        19916      124.647842         0.607552   \n",
       "14               36.50        16340       67.802111         0.330477   \n",
       "15               36.25        14304      239.530312         1.167506   \n",
       "16               35.75        12546      282.906112         1.378926   \n",
       "17               35.50         9315      185.011165         0.901771   \n",
       "18               35.00        11546      446.009058         2.173913   \n",
       "19               34.75         9900      491.150581         2.393939   \n",
       "20               34.25        11715      506.124150         2.466923   \n",
       "21               34.00         9025     1234.394931         6.016620   \n",
       "22               33.50        10838     1487.903995         7.252261   \n",
       "23               33.25        11399     1772.845900         8.641109   \n",
       "\n",
       "        Ratio  years  \n",
       "0    5.005669   1991  \n",
       "1    3.108486   1992  \n",
       "2    1.376049   1993  \n",
       "3    1.713982   1994  \n",
       "4    4.151464   1995  \n",
       "5    1.670109   1996  \n",
       "6    1.425025   1997  \n",
       "7    4.305835   1998  \n",
       "8    5.904543   1999  \n",
       "9    1.755968   2000  \n",
       "10   2.079733   2001  \n",
       "11   2.050569   2002  \n",
       "12   8.613119   2003  \n",
       "13   3.387170   2004  \n",
       "14   1.862695   2005  \n",
       "15   6.635189   2006  \n",
       "16   7.913458   2007  \n",
       "17   5.226304   2008  \n",
       "18  12.743116   2009  \n",
       "19  14.195103   2010  \n",
       "20  14.798952   2011  \n",
       "21  36.520560   2012  \n",
       "22  44.415045   2013  \n",
       "23  53.398973   2014  "
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Dataframe with all the data\n",
    "data_dict={\"years\": years, \"Mammals_obs\":mammal_obs, \"Deer_obs\":deer_obs, \"Percentage_deer\":percentage, \\\n",
    "           \"Comparison_average\":average_norm, \"Actual_deer (Mi)\": actual_deer, \"Discretized_actual\": discrete, \\\n",
    "          \"Normalized_obs\":norm_obs, \"Ratio\":ratio, \"Discrete Ratio\": discrete_ratio}\n",
    "Data_summary=pd.DataFrame(data_dict)\n",
    "\n",
    "Data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Matrix\n",
    "We calculate the transition matrix by counting the occurences of going from hidden state i to hidden state j, and dividing the values of each row by the sum of the row: we check that the obtained probabilities on each row sum up to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the transition matrix, we create a 41 by 41 matrix and calculate the probability of a certain current letter\n",
    "# knowing the previous letter. The rows of this matrix should sum up to 1 \n",
    "# The columns correspond to the current letter and the rows to the previous letter\n",
    "\n",
    "#Emission is probability from hidden to observed\n",
    "\n",
    "#Transition is from hidden to next hidden\n",
    "n=len(discrete_states)\n",
    "transition=np.zeros((n,n))\n",
    "# Add a pseudocount\n",
    "transition=transition+0.05\n",
    "\n",
    "for j in xrange(len(discrete)-1):\n",
    "    for i in xrange(len(discrete_states)):\n",
    "        if discrete[j+1]==discrete_states[i]:\n",
    "            for k in xrange(len(discrete_states)):\n",
    "                if discrete[j]==discrete_states[k]:\n",
    "                    transition[k,i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUMS=np.zeros(n)\n",
    "for i in xrange(len(SUMS)):\n",
    "    SUMS[i]=np.sum(transition[i,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition_f=np.zeros((n,n))\n",
    "for i in xrange(len(SUMS)):\n",
    "    transition_f[i,:]=transition[i,:]/SUMS[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.])"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to verify my calculations, the sum of the rows should be zero\n",
    "SUM2=np.zeros(n)\n",
    "for i in xrange(len(SUM2)):\n",
    "    SUM2[i]=np.sum(transition_f[i,:])\n",
    "SUM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Emission probability\n",
    "emission=np.zeros((n,obs_len))\n",
    "# Add a pseudocount\n",
    "emission=emission+0.05\n",
    "for j in xrange(len(discrete_ratio)-1):\n",
    "    for i in xrange(obs_len):\n",
    "        if discrete_ratio[j]==obs_states[i]:\n",
    "            for k in xrange(len(discrete_states)):\n",
    "                if discrete[j]==discrete_states[k]:\n",
    "                    emission[k,i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SUMS=np.zeros(n)\n",
    "for i in xrange(len(SUMS)):\n",
    "    SUMS[i]=np.sum(emission[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emission_f=np.zeros((n,obs_len))\n",
    "for i in xrange(len(SUMS)):\n",
    "    emission_f[i,:]=emission[i,:]/SUMS[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to verify my calculations, the sum of the rows should be zero\n",
    "SUM2=np.zeros(n)\n",
    "for i in xrange(len(SUM2)):\n",
    "    SUM2[i]=np.sum(emission_f[i,:])\n",
    "SUM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emission_log=np.log(emission_f)\n",
    "transition_log=np.log(transition_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Starting Probability\n",
    "itemindex= np.where(discrete_states==discrete[0])[0][0]\n",
    "\n",
    "starting_prob=np.zeros(n)\n",
    "starting_prob[itemindex]=1\n",
    "np.shape(starting_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.,   4.,   1.,   4.,   4.,   4.,   1.,   4.,   7.,   4.,   4.,\n",
       "         4.,  10.,   4.,   4.,   7.,  10.,   7.,  13.,  16.,  16.,  37.,\n",
       "        46.,  55.])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function takes as input the observed and hiddent states. \n",
    "# It takes the starting probability, the transition and emission matrix and the test data Y.\n",
    "\n",
    "# The function returns Z, which corresponds to the array of the indexes of the corrected letter (which we can \n",
    "# extract later from the state space)\n",
    "\n",
    "def viterbi(hidden, observed, starting_prob, Y, transition_log, emission_log):   \n",
    "    size_test=len(Y)\n",
    "    T1=np.zeros((len(hidden),size_test))\n",
    "    T2=np.zeros((len(hidden),size_test))\n",
    "    index= np.where(observed==Y[0])[0][0]\n",
    "    for i in xrange(len(hidden)):\n",
    "        T1[i,1]=np.log(starting_prob[i])+emission_log[i,index]\n",
    "    for i in range(1,len(Y)):\n",
    "        index= np.where(observed==Y[i])[0][0]\n",
    "        for j in xrange(len(hidden)):\n",
    "            list_val=T1[:,i-1]+transition_log[:,j]+emission_log[j,index]\n",
    "            T1[j,i]=np.max(list_val) \n",
    "            T2[j,i]=np.argmax(list_val) \n",
    "    Z=np.zeros(size_test)  \n",
    "    T_ind=size_test-1\n",
    "    Z[T_ind]=np.argmax(T1[:,T_ind])\n",
    "    \n",
    "    for i in range(T_ind, 1, -1):\n",
    "        Z[i-1]=T2[Z[i], i]\n",
    "    \n",
    "    return Z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,  30.,  29.,  28.,  26.,  28.,  29.,  30.,  31.,  33.,  32.,\n",
       "        30.,  29.,  28.,  26.,  25.,  23.,  22.,  20.,  19.,  17.,  16.,\n",
       "        14.,  13.])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z=viterbi(discrete_states,obs_states, starting_prob, discrete_ratio, transition_log, emission_log)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x108998290>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAF/CAYAAABKX7AhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERHJUgp5ERGRLPX/Aad0MFazCfEbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121d95950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(years,Z,label=\"Estimation\")\n",
    "plt.plot(years,actual_deer,label=\"Actual\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Number of dears in Millions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even though the number of observations of deer increase since 2005, Viterbi algorithm manages to translate the decrease that occured in the actual values since 2000.  While it is not close to the actual values, it did capture their trend which is interesting\n",
    "\n",
    "Note: To explain the increase in number of deer counts, there could also be an increase in the number of deer studies. This raises the question as to whether this is reliable data. Sightings may also depend on where the scientists decided to look for these animals, as it is unlikely there are people sweeping the entirety of the US to look for deer. Much of the data probably depends on scientific study patterns and may not reflect actual deer population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Second order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition=np.zeros((n**2,n**2))\n",
    "transition=transition+0.05\n",
    "\n",
    "for j in xrange(len(discrete)-2):\n",
    "    # Find the index of data_correct[j],[j+1],[j+2]\n",
    "    for i in xrange(len(discrete_states)):\n",
    "        if discrete[j+1]==discrete_states[i]:\n",
    "            for m in xrange(len(discrete_states)):\n",
    "                if discrete[j+2]==discrete_states[m]:\n",
    "                    for k in xrange(len(discrete_states)):\n",
    "                        if discrete[j]==discrete_states[k]:\n",
    "                            transition[k*n+i,i*n+m]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition_f=transition/np.sum(transition, axis=1).reshape(n**2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUMS=np.zeros(n**2)\n",
    "for i in xrange(len(SUMS)):\n",
    "    SUMS[i]=np.sum(transition_f[i,:])\n",
    "SUMS[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emission=np.zeros((n**2,obs_len))\n",
    "emission=emission+0.05\n",
    "\n",
    "for j in xrange(len(discrete_ratio)-2):\n",
    "    for i in xrange(obs_len):\n",
    "        if discrete_ratio[j+1]==obs_states[i]:\n",
    "            for m in xrange(obs_len):\n",
    "                if discrete[j]==discrete_states[m]:\n",
    "                    for k in xrange(len(discrete_states)):\n",
    "                        if discrete[j+1]==discrete_states[k]:\n",
    "                            emission[n*m+k,i]+=1\n",
    "                                    \n",
    "emission_f=emission/np.sum(emission, axis=1).reshape(n**2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUMS=np.zeros(27**2)\n",
    "for i in xrange(len(SUMS)):\n",
    "    SUMS[i]=np.sum(emission_f[i,:])\n",
    "SUMS[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_log=np.log(transition_f)\n",
    "emission_log=np.log(emission_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "## Starting Probability\n",
    "itemindex= np.where(discrete_states==discrete[0])[0][0]\n",
    "itemindex2= np.where(discrete_states==discrete[1])[0][0]\n",
    "\n",
    "starting_prob=np.zeros(n*n)\n",
    "starting_prob[itemindex*n+itemindex2]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi2(hidden, observed, starting_prob, Y, transition_log, emission_log):   \n",
    "    size_test=len(Y)\n",
    "    length=np.shape(transition_log)[0]\n",
    "    T1=np.zeros((length,size_test))\n",
    "    T2=np.zeros((length,size_test))\n",
    "    ind1=np.where(observed==Y[0])[0][0]\n",
    "    for i in xrange(length):\n",
    "        T1[i,1]=np.log(starting_prob[i])+emission_log[i,ind1]\n",
    "    for i in range(1,len(Y)-1):\n",
    "        ind2= np.where(observed==Y[i])[0][0]\n",
    "        for j in xrange(length):\n",
    "            list_val=T1[:,i-1]+transition_log[:,j]+emission_log[j,ind2]\n",
    "            T1[j,i]=np.max(list_val) \n",
    "            T2[j,i]=np.argmax(list_val) \n",
    "    Z=np.zeros(size_test)  \n",
    "    T_ind=size_test-1\n",
    "    Z[T_ind]=np.argmax(T1[:,T_ind])\n",
    "    \n",
    "    for i in range(T_ind, 1, -1):\n",
    "        Z[i-1]=T2[Z[i], i]\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z=viterbi2(discrete_states, obs_states, starting_prob, discrete_ratio, transition_log, emission_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.,  1009.,  1051.,  1094.,  1177.,  1219.,  1261.,  1304.,\n",
       "        1385.,  1342.,  1259.,  1217.,  1174.,  1091.,  1048.,   965.,\n",
       "         922.,   839.,   796.,   713.,   670.,   587.,     0.,     0.])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method does not seem to work properly. Need to rework it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Backward Algorithm\n",
    "\n",
    "Now that we have looked at decoding a sequence over the years, we use the forward–backward algorithm to find the most likely discreteized state for any point in time, in our case any year.\n",
    "The algorithm involves three steps as detailed below:\n",
    "\n",
    "1. computing forward probabilities\n",
    "\n",
    "2. computing backward probabilities\n",
    "\n",
    "3. computing smoothed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fwd_bkw(y, states, starting_prob, transition, emission, obs_states):\n",
    "    L = len(y)\n",
    "    fwd = []\n",
    "    f_prev = {}\n",
    "    # forward part of the algorithm\n",
    "    for i in range(len(y)):\n",
    "        f_curr = {}\n",
    "        ind1=np.where(obs_states==y[i])[0][0] \n",
    "        for j in range(len(states)):\n",
    "            st=states[j]\n",
    "            if i == 0:\n",
    "                # base case for the forward part\n",
    "                prev_f_sum = starting_prob[j]\n",
    "            else:\n",
    "                prev_f_sum = sum(f_prev[states[k]]*transition[k,j] for k in range(len(states)))\n",
    " \n",
    "            f_curr[st] = emission[j,ind1] * prev_f_sum\n",
    " \n",
    "        fwd.append(f_curr)\n",
    "        f_prev = f_curr\n",
    " \n",
    "    bkw = []\n",
    "    b_prev = {}\n",
    "    # backward part of the algorithm\n",
    "    y2=np.append(y,None)\n",
    "    y2=np.delete(y2,[0])\n",
    "    y2=reversed(y2)\n",
    "    for i, y_val in enumerate(y2):\n",
    "        b_curr = {}\n",
    "        for j in range(len(states)):\n",
    "            st=states[j]\n",
    "            if i == 0:\n",
    "                # base case for backward part\n",
    "                b_curr[st] = 1.0\n",
    "            else:\n",
    "                ind2=np.where(obs_states==y_val)[0][0] \n",
    "                b_curr[st] = sum(transition[j,l]*emission[l,ind2]*b_prev[states[l]] for l in range(len(states)))\n",
    " \n",
    "        bkw.insert(0,b_curr)\n",
    "        b_prev = b_curr\n",
    "     \n",
    "    ind3=np.where(obs_states==y[0])[0][0] \n",
    "    p_bkw = sum(starting_prob[l] * emission[l,ind3] * b_curr[states[l]] for l in range(len(states)))\n",
    " \n",
    "    # merging the two parts\n",
    "    posterior = []\n",
    "    for i in range(L):\n",
    "        posterior.append({st: fwd[i][st]*bkw[i][st]/p_bkw for st in states})\n",
    " \n",
    "    return fwd, bkw, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[{30.25: 0.0, 30.5: 0.0, 36.75: 0.0, 37.25: 0.0, 32.25: 0.0, 36.5: 0.0, 33.25: 0.0, 39.75: 0.0, 37.5: 0.0, 30.0: 0.0, 31.0: 0.0, 32.0: 0.0, 33.0: 0.0, 34.0: 0.0, 33.75: 0.0, 36.0: 0.0, 37.0: 0.0, 31.5: 0.0, 39.0: 0.0, 40.0: 0.0, 34.25: 0.0, 34.5: 0.0, 35.0: 0.0, 31.25: 0.0, 38.25: 0.0, 31.75: 0.0, 34.75: 0.0, 39.25: 0.0, 38.5: 0.0, 38.75: 0.0, 35.25: 0.0, 37.75: 0.0, 35.5: 1.0, 32.75: 0.0, 33.5: 0.0, 35.75: 0.0, 38.0: 0.0, 39.5: 0.0, 36.25: 0.0, 30.75: 0.0, 32.5: 0.0}, {30.25: 0.0029975632422003917, 30.5: 0.0029975632422003917, 36.75: 0.0029975632422003917, 37.25: 0.00032148136564997772, 32.25: 0.0029975632422003917, 36.5: 0.014166791411121897, 33.25: 0.0029975632422003917, 39.75: 0.0029975632422003917, 37.5: 0.063186359282828022, 30.0: 0.0029975632422003917, 31.0: 0.0029975632422003917, 32.0: 0.0029975632422003917, 33.0: 0.0029975632422003917, 34.0: 0.00068174358198450991, 33.75: 0.0029975632422003917, 36.0: 0.00070367465868451931, 37.0: 0.060975293101257419, 31.5: 0.0029975632422003917, 39.0: 0.0029975632422003917, 40.0: 0.0029975632422003917, 34.25: 0.00067549472872080853, 34.5: 0.0029975632422003917, 35.0: 0.014180150738301816, 31.25: 0.0029975632422003917, 38.25: 0.014995718827005549, 31.75: 0.0029975632422003917, 34.75: 0.00067525391977726803, 39.25: 0.0029975632422003917, 38.5: 0.0029975632422003917, 38.75: 0.0029975632422003917, 35.25: 0.0029975632422003917, 37.75: 0.00073699867380884584, 35.5: 0.00031148096243293515, 32.75: 0.0029975632422003917, 33.5: 0.00085622136476226878, 35.75: 0.73149557284868538, 38.0: 0.013644010982595652, 39.5: 0.0029975632422003917, 36.25: 0.0074546724973732258, 30.75: 0.0029975632422003917, 32.5: 0.0029975632422003917}, {30.25: 0.0052019635063501584, 30.5: 0.0052019635063501584, 36.75: 0.0052019635063501584, 37.25: 0.15145375587655768, 32.25: 0.0052019635063501584, 36.5: 0.0074023464799864609, 33.25: 0.0054329158850344476, 39.75: 0.0052019635063501584, 37.5: 0.001074874756440427, 30.0: 0.0052019635063501584, 31.0: 0.0052019635063501584, 32.0: 0.0052019635063501584, 33.0: 0.0052019635063501584, 34.0: 0.0011815086581762149, 33.75: 0.0052019635063501584, 36.0: 0.6717268548620644, 37.0: 0.0029519568735258323, 31.5: 0.0052019635063501584, 39.0: 0.0052019635063501584, 40.0: 0.0052019635063501584, 34.25: 0.001175843876795424, 34.5: 0.0052019635063501584, 35.0: 0.0011479228021225576, 31.25: 0.0052019635063501584, 38.25: 0.0026283253662987981, 31.75: 0.0052019635063501584, 34.75: 0.0021751662197304661, 39.25: 0.0052019635063501584, 38.5: 0.0052019635063501584, 38.75: 0.0052019635063501584, 35.25: 0.0052019635063501584, 37.75: 0.010957390082600377, 35.5: 0.0066096395460378482, 32.75: 0.0052019635063501584, 33.5: 0.0013285064693830907, 35.75: 0.00076319244234321706, 38.0: 0.0038654880148352375, 39.5: 0.0052019635063501584, 36.25: 0.0032771876356636445, 30.75: 0.0052019635063501584, 32.5: 0.0052019635063501584}, {30.25: 0.0034417987417907484, 30.5: 0.0034417987417907484, 36.75: 0.0034417987417907484, 37.25: 0.001080480713128894, 32.25: 0.0034417987417907484, 36.5: 0.049698132293297163, 33.25: 0.0036370401113560266, 39.75: 0.0034417987417907484, 37.5: 0.041089565969538652, 30.0: 0.0034417987417907484, 31.0: 0.0034417987417907484, 32.0: 0.0034417987417907484, 33.0: 0.0034417987417907484, 34.0: 0.00079317575012336752, 33.75: 0.0034417987417907484, 36.0: 0.0015841955521641851, 37.0: 0.18325253693986499, 31.5: 0.0034417987417907484, 39.0: 0.0034417987417907484, 40.0: 0.0034417987417907484, 34.25: 0.00082541412565287928, 34.5: 0.0034417987417907484, 35.0: 0.00092253262043622713, 31.25: 0.0034417987417907484, 38.25: 0.1003909198816655, 31.75: 0.0034417987417907484, 34.75: 0.0007880828223677883, 39.25: 0.0034417987417907484, 38.5: 0.0034417987417907484, 38.75: 0.0034417987417907484, 35.25: 0.0034417987417907484, 37.75: 0.0018612790064960563, 35.5: 0.0004712247646172422, 32.75: 0.0034417987417907484, 33.5: 0.00089870173137351732, 35.75: 0.0094061355928877991, 38.0: 0.027850624947946576, 39.5: 0.0034417987417907484, 36.25: 0.49284678737410542, 30.75: 0.0034417987417907484, 32.5: 0.0034417987417907484}, {30.25: 0.0027014649655939145, 30.5: 0.0027014649655939145, 36.75: 0.0027014649655939145, 37.25: 0.015348642275711635, 32.25: 0.0027014649655939145, 36.5: 0.5938225133926357, 33.25: 0.0028415076799576107, 39.75: 0.0027014649655939145, 37.5: 0.023128516955127604, 30.0: 0.0027014649655939145, 31.0: 0.0027014649655939145, 32.0: 0.0027014649655939145, 33.0: 0.0027014649655939145, 34.0: 0.00062487643866384625, 33.75: 0.0027014649655939145, 36.0: 0.0012532892490953818, 37.0: 0.039380897723478497, 31.5: 0.0027014649655939145, 39.0: 0.0027014649655939145, 40.0: 0.0027014649655939145, 34.25: 0.00061723099351404553, 34.5: 0.0027014649655939145, 35.0: 0.00059984729564289084, 31.25: 0.0027014649655939145, 38.25: 0.022703902163910512, 31.75: 0.0027014649655939145, 34.75: 0.0006221452809574865, 39.25: 0.0027014649655939145, 38.5: 0.0027014649655939145, 38.75: 0.0027014649655939145, 35.25: 0.0027014649655939145, 37.75: 0.0040839973401532092, 35.5: 0.00091372122031464689, 32.75: 0.0027014649655939145, 33.5: 0.00070035462162259588, 35.75: 0.037007498850544204, 38.0: 0.15791669589648946, 39.5: 0.0027014649655939145, 36.25: 0.033599203447926142, 30.75: 0.0027014649655939145, 32.5: 0.0027014649655939145}, {30.25: 0.0026363959325639091, 30.5: 0.0026363959325639091, 36.75: 0.0026363959325639091, 37.25: 0.001115207587324039, 32.25: 0.0026363959325639091, 36.5: 0.040871920146036765, 33.25: 0.0027440335762869239, 39.75: 0.0026363959325639091, 37.5: 0.2161007631521864, 30.0: 0.0026363959325639091, 31.0: 0.0026363959325639091, 32.0: 0.0026363959325639091, 33.0: 0.0026363959325639091, 34.0: 0.00062592144141019766, 33.75: 0.0026363959325639091, 36.0: 0.0021758123270425229, 37.0: 0.55075334070000281, 31.5: 0.0026363959325639091, 39.0: 0.0026363959325639091, 40.0: 0.0026363959325639091, 34.25: 0.00061930341875200028, 34.5: 0.0026363959325639091, 35.0: 0.00061069374260900721, 31.25: 0.0026363959325639091, 38.25: 0.020798051884741681, 31.75: 0.0026363959325639091, 34.75: 0.00061797458929877154, 39.25: 0.0026363959325639091, 38.5: 0.0026363959325639091, 38.75: 0.0026363959325639091, 35.25: 0.0026363959325639091, 37.75: 0.0015817628645303076, 35.5: 0.00093339238596963289, 32.75: 0.0026363959325639091, 33.5: 0.00078416657176153947, 35.75: 0.032014900741361048, 38.0: 0.022237065329098825, 39.5: 0.0026363959325639091, 36.25: 0.042142187160052719, 30.75: 0.0026363959325639091, 32.5: 0.0026363959325639091}, {30.25: 0.0053256215604604628, 30.5: 0.0053256215604604628, 36.75: 0.0053256215604604628, 37.25: 0.74699540460622482, 32.25: 0.0053256215604604628, 36.5: 0.011248333505528639, 33.25: 0.0055373530109410971, 39.75: 0.0053256215604604628, 37.5: 0.0013580860592979933, 30.0: 0.0053256215604604628, 31.0: 0.0053256215604604628, 32.0: 0.0053256215604604628, 33.0: 0.0053256215604604628, 34.0: 0.0012218787241209516, 33.75: 0.0053256215604604628, 36.0: 0.057508758907109415, 37.0: 0.00586436516260709, 31.5: 0.0053256215604604628, 39.0: 0.0053256215604604628, 40.0: 0.0053256215604604628, 34.25: 0.0012099815071343098, 34.5: 0.0053256215604604628, 35.0: 0.0012306391618335378, 31.25: 0.0053256215604604628, 38.25: 0.0023854999893200071, 31.75: 0.0053256215604604628, 34.75: 0.0012090148116891603, 39.25: 0.0053256215604604628, 38.5: 0.0053256215604604628, 38.75: 0.0053256215604604628, 35.25: 0.0053256215604604628, 37.75: 0.0067382760813483227, 35.5: 0.0017970264661348505, 32.75: 0.0053256215604604628, 33.5: 0.0014002921789482818, 35.75: 0.0020950696379490956, 38.0: 0.016499703640492837, 39.5: 0.0053256215604604628, 36.25: 0.007885399098266797, 30.75: 0.0053256215604604628, 32.5: 0.0053256215604604628}, {30.25: 0.0029618828892916424, 30.5: 0.0029618828892916424, 36.75: 0.0029618828892916424, 37.25: 0.0003736520015478418, 32.25: 0.0029618828892916424, 36.5: 0.044784257252602974, 33.25: 0.0032071291795547573, 39.75: 0.0029618828892916424, 37.5: 0.67981443338212311, 30.0: 0.0029618828892916424, 31.0: 0.0029618828892916424, 32.0: 0.0029618828892916424, 33.0: 0.0029618828892916424, 34.0: 0.00071905820513763145, 33.75: 0.0029618828892916424, 36.0: 0.0021784678359813114, 37.0: 0.11309058604833987, 31.5: 0.0029618828892916424, 39.0: 0.0029618828892916424, 40.0: 0.0029618828892916424, 34.25: 0.00071349396985497112, 34.5: 0.0029618828892916424, 35.0: 0.00069688090599493661, 31.25: 0.0029618828892916424, 38.25: 0.017926139506881406, 31.75: 0.0029618828892916424, 34.75: 0.00071425764754832512, 39.25: 0.0029618828892916424, 38.5: 0.0029618828892916424, 38.75: 0.0029618828892916424, 35.25: 0.0029618828892916424, 37.75: 0.00077398020928300636, 35.5: 0.0003412925662805326, 32.75: 0.0029618828892916424, 33.5: 0.00087378440888512493, 35.75: 0.019337124501054754, 38.0: 0.014564842233649049, 39.5: 0.0029618828892916424, 36.25: 0.028805430802279409, 30.75: 0.0029618828892916424, 32.5: 0.0029618828892916424}, {30.25: 0.0048547534420853656, 30.5: 0.0048547534420853656, 36.75: 0.0048547534420853656, 37.25: 0.029861679059999934, 32.25: 0.0048547534420853656, 36.5: 0.024778701071133571, 33.25: 0.0050595543534511069, 39.75: 0.0048547534420853656, 37.5: 0.00098513535182393093, 30.0: 0.0048547534420853656, 31.0: 0.0048547534420853656, 32.0: 0.0048547534420853656, 33.0: 0.0048547534420853656, 34.0: 0.0011002963761099218, 33.75: 0.0048547534420853656, 36.0: 0.0045272903746943231, 37.0: 0.0027691574938061877, 31.5: 0.0048547534420853656, 39.0: 0.0048547534420853656, 40.0: 0.0048547534420853656, 34.25: 0.0010951145987822121, 34.5: 0.0048547534420853656, 35.0: 0.0010711160158847432, 31.25: 0.0048547534420853656, 38.25: 0.0024557123450784138, 31.75: 0.0048547534420853656, 34.75: 0.0010938298252373441, 39.25: 0.0048547534420853656, 38.5: 0.0048547534420853656, 38.75: 0.0048547534420853656, 35.25: 0.0048547534420853656, 37.75: 0.70055597269275338, 35.5: 0.037237262093615102, 32.75: 0.0048547534420853656, 33.5: 0.001237156259701139, 35.75: 0.0012276474449815088, 38.0: 0.0037338343121790019, 39.5: 0.0048547534420853656, 36.25: 0.064696457720717943, 30.75: 0.0048547534420853656, 32.5: 0.0048547534420853656}, {30.25: 0.0027300563533187985, 30.5: 0.0027300563533187985, 36.75: 0.0027300563533187985, 37.25: 0.00088766851397170394, 32.25: 0.0027300563533187985, 36.5: 0.076121664493834063, 33.25: 0.0029118280774350375, 39.75: 0.0027300563533187985, 37.5: 0.019139273848649222, 30.0: 0.0027300563533187985, 31.0: 0.0027300563533187985, 32.0: 0.0027300563533187985, 33.0: 0.0027300563533187985, 34.0: 0.00063549683887767841, 33.75: 0.0027300563533187985, 36.0: 0.0011720968237304004, 37.0: 0.098233254782114809, 31.5: 0.0027300563533187985, 39.0: 0.0027300563533187985, 40.0: 0.0027300563533187985, 34.25: 0.00063216338265198143, 34.5: 0.0027300563533187985, 35.0: 0.0015806371747916098, 31.25: 0.0027300563533187985, 38.25: 0.64082352735790638, 31.75: 0.0027300563533187985, 34.75: 0.00063100941853368609, 39.25: 0.0027300563533187985, 38.5: 0.0027300563533187985, 38.75: 0.0027300563533187985, 35.25: 0.0027300563533187985, 37.75: 0.0015366229699091212, 35.5: 0.00038928767004409929, 32.75: 0.0027300563533187985, 33.5: 0.00071947383516136746, 35.75: 0.02244528502385228, 38.0: 0.022420815054537063, 39.5: 0.0027300563533187985, 36.25: 0.044198542254347079, 30.75: 0.0027300563533187985, 32.5: 0.0027300563533187985}, {30.25: 0.0025652001998348866, 30.5: 0.0025652001998348866, 36.75: 0.0025652001998348866, 37.25: 0.0085469543602757787, 32.25: 0.0025652001998348866, 36.5: 0.1822932469374107, 33.25: 0.002677288807546742, 39.75: 0.0025652001998348866, 37.5: 0.02041178579801314, 30.0: 0.0025652001998348866, 31.0: 0.0025652001998348866, 32.0: 0.0025652001998348866, 33.0: 0.0025652001998348866, 34.0: 0.00059271326637183987, 33.75: 0.0025652001998348866, 36.0: 0.002562661367907222, 37.0: 0.05185982312028381, 31.5: 0.0025652001998348866, 39.0: 0.0025652001998348866, 40.0: 0.0025652001998348866, 34.25: 0.0005846462827291956, 34.5: 0.0025652001998348866, 35.0: 0.00057083001295057804, 31.25: 0.0025652001998348866, 38.25: 0.022608495230711317, 31.75: 0.0025652001998348866, 34.75: 0.0006210977617013587, 39.25: 0.0025652001998348866, 38.5: 0.0025652001998348866, 38.75: 0.0025652001998348866, 35.25: 0.0025652001998348866, 37.75: 0.00227151544886237, 35.5: 0.00096412442671306474, 32.75: 0.0025652001998348866, 33.5: 0.00067140660739634648, 35.75: 0.0082899709370855695, 38.0: 0.59838834461009427, 39.5: 0.0025652001998348866, 36.25: 0.034520290227907875, 30.75: 0.0025652001998348866, 32.5: 0.0025652001998348866}, {30.25: 0.0027771764457703708, 30.5: 0.0027771764457703708, 36.75: 0.0027771764457703708, 37.25: 0.0012879158643536971, 32.25: 0.0027771764457703708, 36.5: 0.051433319327459884, 33.25: 0.0028901208072834726, 39.75: 0.0027771764457703708, 37.5: 0.57080341723313899, 30.0: 0.0027771764457703708, 31.0: 0.0027771764457703708, 32.0: 0.0027771764457703708, 33.0: 0.0027771764457703708, 34.0: 0.0006708679547559721, 33.75: 0.0027771764457703708, 36.0: 0.0010217057022882841, 37.0: 0.2054677664948702, 31.5: 0.0027771764457703708, 39.0: 0.0027771764457703708, 40.0: 0.0027771764457703708, 34.25: 0.00066434861788300099, 34.5: 0.0027771764457703708, 35.0: 0.00066367876171281393, 31.25: 0.0027771764457703708, 38.25: 0.015373013009887306, 31.75: 0.0027771764457703708, 34.75: 0.0006617444900506276, 39.25: 0.0027771764457703708, 38.5: 0.0027771764457703708, 38.75: 0.0027771764457703708, 35.25: 0.0027771764457703708, 37.75: 0.001807756985383417, 35.5: 0.00085072179410476104, 32.75: 0.0027771764457703708, 33.5: 0.00087648456551914504, 35.75: 0.016529238499802208, 38.0: 0.023639374880498644, 39.5: 0.0027771764457703708, 36.25: 0.038706290312517488, 30.75: 0.0027771764457703708, 32.5: 0.0027771764457703708}, {30.25: 0.0068027089653912099, 30.5: 0.0068027089653912099, 36.75: 0.0068027089653912099, 37.25: 0.70108201053764063, 32.25: 0.0068027089653912099, 36.5: 0.023070882548655813, 33.25: 0.0070763362835773898, 39.75: 0.0068027089653912099, 37.5: 0.0018669005355615956, 30.0: 0.0068027089653912099, 31.0: 0.0068027089653912099, 32.0: 0.0068027089653912099, 33.0: 0.0068027089653912099, 34.0: 0.0015482808711146932, 33.75: 0.0068027089653912099, 36.0: 0.011457408978215542, 37.0: 0.0066828952734947619, 31.5: 0.0068027089653912099, 39.0: 0.0068027089653912099, 40.0: 0.0068027089653912099, 34.25: 0.0015383238587893537, 34.5: 0.0068027089653912099, 35.0: 0.0015180598309819514, 31.25: 0.0068027089653912099, 38.25: 0.0050938942842237798, 31.75: 0.0068027089653912099, 34.75: 0.0015380763911145552, 39.25: 0.0068027089653912099, 38.5: 0.0068027089653912099, 38.75: 0.0068027089653912099, 35.25: 0.0068027089653912099, 37.75: 0.026221197246558154, 35.5: 0.0016631756615827933, 32.75: 0.0068027089653912099, 33.5: 0.0017588764541524712, 35.75: 0.032222192008793116, 38.0: 0.0047474801811028776, 39.5: 0.0068027089653912099, 36.25: 0.0076489938850504528, 30.75: 0.0068027089653912099, 32.5: 0.0068027089653912099}, {30.25: 0.0033664677857236764, 30.5: 0.0033664677857236764, 36.75: 0.0033664677857236764, 37.25: 0.0013888040499775119, 32.25: 0.0033664677857236764, 36.5: 0.03815610041050603, 33.25: 0.0036492742144995094, 39.75: 0.0033664677857236764, 37.5: 0.10894058113856649, 30.0: 0.0033664677857236764, 31.0: 0.0033664677857236764, 32.0: 0.0033664677857236764, 33.0: 0.0033664677857236764, 34.0: 0.00080400024663757042, 33.75: 0.0033664677857236764, 36.0: 0.002643554827796614, 37.0: 0.57178245117965054, 31.5: 0.0033664677857236764, 39.0: 0.0033664677857236764, 40.0: 0.0033664677857236764, 34.25: 0.00079855385316397786, 34.5: 0.0033664677857236764, 35.0: 0.00078217520667263113, 31.25: 0.0033664677857236764, 38.25: 0.046030067790345221, 31.75: 0.0033664677857236764, 34.75: 0.00079732879386529775, 39.25: 0.0033664677857236764, 38.5: 0.0033664677857236764, 38.75: 0.0033664677857236764, 35.25: 0.0033664677857236764, 37.75: 0.0015481541986424692, 35.5: 0.0042482736702068903, 32.75: 0.0033664677857236764, 33.5: 0.00092990081120120018, 35.75: 0.01002666362871938, 38.0: 0.043735872767155362, 39.5: 0.0033664677857236764, 36.25: 0.082943016355024338, 30.75: 0.0033664677857236764, 32.5: 0.0033664677857236764}, {30.25: 0.0040688106324409251, 30.5: 0.0040688106324409251, 36.75: 0.0040688106324409251, 37.25: 0.0048996135902929176, 32.25: 0.0040688106324409251, 36.5: 0.59120161718331421, 33.25: 0.0042374948762150333, 39.75: 0.0040688106324409251, 37.5: 0.060034921518902086, 30.0: 0.0040688106324409251, 31.0: 0.0040688106324409251, 32.0: 0.0040688106324409251, 33.0: 0.0040688106324409251, 34.0: 0.00093797002240776845, 33.75: 0.0040688106324409251, 36.0: 0.0065601087897634225, 37.0: 0.030940681808231354, 31.5: 0.0040688106324409251, 39.0: 0.0040688106324409251, 40.0: 0.0040688106324409251, 34.25: 0.00092734825435271374, 34.5: 0.0040688106324409251, 35.0: 0.00092931027382324189, 31.25: 0.0040688106324409251, 38.25: 0.019462021743730195, 31.75: 0.0040688106324409251, 34.75: 0.00092615823893716406, 39.25: 0.0040688106324409251, 38.5: 0.0040688106324409251, 38.75: 0.0040688106324409251, 35.25: 0.0040688106324409251, 37.75: 0.0058218843739499503, 35.5: 0.00057937643753977345, 32.75: 0.0040688106324409251, 33.5: 0.0010749661950450692, 35.75: 0.11575380504809889, 38.0: 0.041552196554613376, 39.5: 0.0040688106324409251, 36.25: 0.016509069912199519, 30.75: 0.0040688106324409251, 32.5: 0.0040688106324409251}, {30.25: 0.0040232579543551432, 30.5: 0.0040232579543551432, 36.75: 0.0040232579543551432, 37.25: 0.0017201435570871342, 32.25: 0.0040232579543551432, 36.5: 0.0013765090229148321, 33.25: 0.004214315171179173, 39.75: 0.0040232579543551432, 37.5: 0.0022947574064455553, 30.0: 0.0040232579543551432, 31.0: 0.0040232579543551432, 32.0: 0.0040232579543551432, 33.0: 0.0040232579543551432, 34.0: 0.00095898897531625097, 33.75: 0.0040232579543551432, 36.0: 0.0014262705187040956, 37.0: 0.004702021015122247, 31.5: 0.0040232579543551432, 39.0: 0.0040232579543551432, 40.0: 0.0040232579543551432, 34.25: 0.00094813992737483456, 34.5: 0.0040232579543551432, 35.0: 0.00093095025027603107, 31.25: 0.0040232579543551432, 38.25: 0.0011723902232030836, 31.75: 0.0040232579543551432, 34.75: 0.00094777041564359009, 39.25: 0.0040232579543551432, 38.5: 0.0040232579543551432, 38.75: 0.0040232579543551432, 35.25: 0.0040232579543551432, 37.75: 0.048990852429839582, 35.5: 0.26386100674718577, 32.75: 0.0040232579543551432, 33.5: 0.0011924642125770448, 35.75: 0.00080349663752322898, 38.0: 0.0017900422114195029, 39.5: 0.0040232579543551432, 36.25: 0.56611169037366382, 30.75: 0.0040232579543551432, 32.5: 0.0040232579543551432}, {30.25: 0.0043066920750673265, 30.5: 0.0043066920750673265, 36.75: 0.0043066920750673265, 37.25: 0.011624512500839864, 32.25: 0.0043066920750673265, 36.5: 0.0033711542046084113, 33.25: 0.0046200820519560837, 39.75: 0.0043066920750673265, 37.5: 0.0010382883974148084, 30.0: 0.0043066920750673265, 31.0: 0.0043066920750673265, 32.0: 0.0043066920750673265, 33.0: 0.0043066920750673265, 34.0: 0.0010186868655188445, 33.75: 0.0043066920750673265, 36.0: 0.0013821661416799779, 37.0: 0.00051617371943193306, 31.5: 0.0043066920750673265, 39.0: 0.0043066920750673265, 40.0: 0.0043066920750673265, 34.25: 0.0010110799303892489, 34.5: 0.0043066920750673265, 35.0: 0.0029068064477039209, 31.25: 0.0043066920750673265, 38.25: 0.0044812980515519163, 31.75: 0.0043066920750673265, 34.75: 0.0010095034361452507, 39.25: 0.0043066920750673265, 38.5: 0.0043066920750673265, 38.75: 0.0043066920750673265, 35.25: 0.0043066920750673265, 37.75: 0.0010412485072358898, 35.5: 0.0004546922167966931, 32.75: 0.0043066920750673265, 33.5: 0.0011781508271809093, 35.75: 0.85947428366610013, 38.0: 0.0010010954231127955, 39.5: 0.0043066920750673265, 36.25: 0.00051016781071644098, 30.75: 0.0043066920750673265, 32.5: 0.0043066920750673265}, {30.25: 0.0022341216897262934, 30.5: 0.0022341216897262934, 36.75: 0.0022341216897262934, 37.25: 0.00023874987192190711, 32.25: 0.0022341216897262934, 36.5: 0.00023820674455770672, 33.25: 0.0024485585163322096, 39.75: 0.0022341216897262934, 37.5: 0.00049156801864092144, 30.0: 0.0022341216897262934, 31.0: 0.0022341216897262934, 32.0: 0.0022341216897262934, 33.0: 0.0022341216897262934, 34.0: 0.00054075599013727498, 33.75: 0.0022341216897262934, 36.0: 0.0034972280689130257, 37.0: 0.00050696224036160498, 31.5: 0.0022341216897262934, 39.0: 0.0022341216897262934, 40.0: 0.0022341216897262934, 34.25: 0.00053657313808846312, 34.5: 0.0022341216897262934, 35.0: 0.00053367268483127286, 31.25: 0.0022341216897262934, 38.25: 0.0005371406408875947, 31.75: 0.0022341216897262934, 34.75: 0.00062454333023566854, 39.25: 0.0022341216897262934, 38.5: 0.0022341216897262934, 38.75: 0.0022341216897262934, 35.25: 0.0022341216897262934, 37.75: 0.010796662228604832, 35.5: 0.91781250108629175, 32.75: 0.0022341216897262934, 33.5: 0.00062773750862707217, 35.75: 0.00024311144764409839, 38.0: 0.00067977812066159077, 39.5: 0.0022341216897262934, 36.25: 0.006027329809830043, 30.75: 0.0022341216897262934, 32.5: 0.0022341216897262934}, {30.25: 0.0016430706810447284, 30.5: 0.0016430706810447284, 36.75: 0.0016430706810447284, 37.25: 0.00018074697885817252, 32.25: 0.0016430706810447284, 36.5: 0.00029876503058358524, 33.25: 0.0017600575345843319, 39.75: 0.0016430706810447284, 37.5: 0.00018435653990275634, 30.0: 0.0016430706810447284, 31.0: 0.0016430706810447284, 32.0: 0.0016430706810447284, 33.0: 0.0016430706810447284, 34.0: 0.00038933702214947921, 33.75: 0.0016430706810447284, 36.0: 0.00036151298300974753, 37.0: 0.00016978621926611493, 31.5: 0.0016430706810447284, 39.0: 0.0016430706810447284, 40.0: 0.0016430706810447284, 34.25: 0.0003902785316212701, 34.5: 0.0016430706810447284, 35.0: 0.95184709187268801, 31.25: 0.0016430706810447284, 38.25: 0.00087499480048189705, 31.75: 0.0016430706810447284, 34.75: 0.00075674386455344158, 39.25: 0.0016430706810447284, 38.5: 0.0016430706810447284, 38.75: 0.0016430706810447284, 35.25: 0.0016430706810447284, 37.75: 0.00038309328723976869, 35.5: 0.00017829269545702956, 32.75: 0.0016430706810447284, 33.5: 0.00045142030504729364, 35.75: 0.0017231295912917099, 38.0: 0.0003757152417504314, 39.5: 0.0016430706810447284, 36.25: 0.00024098115643928313, 30.75: 0.0016430706810447284, 32.5: 0.0016430706810447284}, {30.25: 0.001346400060192649, 30.5: 0.001346400060192649, 36.75: 0.001346400060192649, 37.25: 0.00013949123853961728, 32.25: 0.001346400060192649, 36.5: 0.00014064756131157885, 33.25: 0.0014306856732718809, 39.75: 0.001346400060192649, 37.5: 0.00014853446009487517, 30.0: 0.001346400060192649, 31.0: 0.001346400060192649, 32.0: 0.001346400060192649, 33.0: 0.001346400060192649, 34.0: 0.00032149262977333742, 33.75: 0.001346400060192649, 36.0: 0.00036729778088786787, 37.0: 0.00014212756251691163, 31.5: 0.001346400060192649, 39.0: 0.001346400060192649, 40.0: 0.001346400060192649, 34.25: 0.006654084809433059, 34.5: 0.001346400060192649, 35.0: 0.00065202505679553971, 31.25: 0.001346400060192649, 38.25: 0.00031540402215212197, 31.75: 0.001346400060192649, 34.75: 0.95589704777179874, 39.25: 0.001346400060192649, 38.5: 0.001346400060192649, 38.75: 0.001346400060192649, 35.25: 0.001346400060192649, 37.75: 0.00030633564055533921, 35.5: 0.00017346346083335452, 32.75: 0.001346400060192649, 33.5: 0.00037691415707696499, 35.75: 0.000144801758522461, 38.0: 0.00032969781581378415, 39.5: 0.001346400060192649, 36.25: 0.00014634715599734394, 30.75: 0.001346400060192649, 32.5: 0.001346400060192649}, {30.25: 0.0015693302196040475, 30.5: 0.0015693302196040475, 36.75: 0.0015693302196040475, 37.25: 0.00016570058654995798, 32.25: 0.0015693302196040475, 36.5: 0.00016534673103383974, 33.25: 0.0016478143055780816, 39.75: 0.0015693302196040475, 37.5: 0.0001783859188554956, 30.0: 0.0015693302196040475, 31.0: 0.0015693302196040475, 32.0: 0.0015693302196040475, 33.0: 0.0015693302196040475, 34.0: 0.00075800991061589218, 33.75: 0.0015693302196040475, 36.0: 0.00034868262181744238, 37.0: 0.00016513692514100346, 31.5: 0.0015693302196040475, 39.0: 0.0015693302196040475, 40.0: 0.0015693302196040475, 34.25: 0.94855793462122118, 34.5: 0.0015693302196040475, 35.0: 0.00036785914280098436, 31.25: 0.0015693302196040475, 38.25: 0.00037357071084501576, 31.75: 0.0015693302196040475, 34.75: 0.0078875983780433336, 39.25: 0.0015693302196040475, 38.5: 0.0015693302196040475, 38.75: 0.0015693302196040475, 35.25: 0.0015693302196040475, 37.75: 0.00036620654449538394, 35.5: 0.00016987456299349834, 32.75: 0.0015693302196040475, 33.5: 0.00047988256276659965, 35.75: 0.00017354049404672323, 38.0: 0.00035902862402091394, 39.5: 0.0015693302196040475, 36.25: 0.00017150208867550105, 30.75: 0.0015693302196040475, 32.5: 0.0015693302196040475}, {30.25: 0.0028711867760288379, 30.5: 0.0028711867760288379, 36.75: 0.0028711867760288379, 37.25: 0.00031642087778376075, 32.25: 0.0028711867760288379, 36.5: 0.00031517974291107983, 33.25: 0.0030073372173944042, 39.75: 0.0028711867760288379, 37.5: 0.00034506465543471097, 30.0: 0.0028711867760288379, 31.0: 0.0028711867760288379, 32.0: 0.0028711867760288379, 33.0: 0.0028711867760288379, 34.0: 0.91926123122881265, 33.75: 0.0028711867760288379, 36.0: 0.00065200816882094088, 37.0: 0.00031496384893016507, 31.5: 0.0028711867760288379, 39.0: 0.0028711867760288379, 40.0: 0.0028711867760288379, 34.25: 0.0013659937870289694, 34.5: 0.0028711867760288379, 35.0: 0.00069908396986096224, 31.25: 0.0028711867760288379, 38.25: 0.00071016489196008262, 31.75: 0.0028711867760288379, 34.75: 0.00071674878800850742, 39.25: 0.0028711867760288379, 38.5: 0.0028711867760288379, 38.75: 0.0028711867760288379, 35.25: 0.0028711867760288379, 37.75: 0.00069982248895193483, 35.5: 0.00033103373918985966, 32.75: 0.0028711867760288379, 33.5: 0.0010259205767147895, 35.75: 0.00033504456682518992, 38.0: 0.00067163077128193035, 39.5: 0.0028711867760288379, 36.25: 0.00032386805539588032, 30.75: 0.0028711867760288379, 32.5: 0.0028711867760288379}, {30.25: 0.0072762396331836066, 30.5: 0.0072762396331836066, 36.75: 0.0072762396331836066, 37.25: 0.00088464822434034408, 32.25: 0.0072762396331836066, 36.5: 0.00088462632759996561, 33.25: 0.0076478062521021439, 39.75: 0.0072762396331836066, 37.5: 0.00097038034436847651, 30.0: 0.0072762396331836066, 31.0: 0.0072762396331836066, 32.0: 0.0072762396331836066, 33.0: 0.0072762396331836066, 34.0: 0.0020133977847280483, 33.75: 0.0072762396331836066, 36.0: 0.0017466255963232101, 37.0: 0.00088420573974177608, 31.5: 0.0072762396331836066, 39.0: 0.0072762396331836066, 40.0: 0.0072762396331836066, 34.25: 0.0019318090672666788, 34.5: 0.0072762396331836066, 35.0: 0.0018809146107581752, 31.25: 0.0072762396331836066, 38.25: 0.0019296819888394647, 31.75: 0.0072762396331836066, 34.75: 0.0019295891813083412, 39.25: 0.0072762396331836066, 38.5: 0.0072762396331836066, 38.75: 0.0072762396331836066, 35.25: 0.0072762396331836066, 37.75: 0.0018827303939872022, 35.5: 0.00092600806710586056, 32.75: 0.0072762396331836066, 33.5: 0.79621272954517763, 35.75: 0.00094575671216147537, 38.0: 0.0017930961779481314, 39.5: 0.0072762396331836066, 36.25: 0.00090624278983471003, 30.75: 0.0072762396331836066, 32.5: 0.0072762396331836066}, {30.25: 0.023098134887510852, 30.5: 0.023098134887510852, 36.75: 0.023098134887510852, 37.25: 0.0044231824265059672, 32.25: 0.023098134887510852, 36.5: 0.004423077955275254, 33.25: 0.3475610157420147, 39.75: 0.023098134887510852, 37.5: 0.004532841871043386, 30.0: 0.023098134887510852, 31.0: 0.023098134887510852, 32.0: 0.023098134887510852, 33.0: 0.023098134887510852, 34.0: 0.0075081995364641397, 33.75: 0.023098134887510852, 36.0: 0.0073190626922127163, 37.0: 0.0044209425992492724, 31.5: 0.023098134887510852, 39.0: 0.023098134887510852, 40.0: 0.023098134887510852, 34.25: 0.0075078090497536143, 34.5: 0.023098134887510852, 35.0: 0.0073159163789345873, 31.25: 0.023098134887510852, 38.25: 0.0074995664039313832, 31.75: 0.023098134887510852, 34.75: 0.0074992470004874951, 39.25: 0.023098134887510852, 38.5: 0.023098134887510852, 38.75: 0.023098134887510852, 35.25: 0.023098134887510852, 37.75: 0.0073229856783593849, 35.5: 0.0043316901647789553, 32.75: 0.023098134887510852, 33.5: 0.0075225513142110796, 35.75: 0.004421220950686173, 38.0: 0.0075078253749650088, 39.5: 0.023098134887510852, 36.25: 0.0045276275608646952, 30.75: 0.023098134887510852, 32.5: 0.023098134887510852}]\n"
     ]
    }
   ],
   "source": [
    "fwd, bkw, posterior = fwd_bkw(discrete_ratio, discrete_states, starting_prob, transition_f, emission_f, obs_states)\n",
    "print len(posterior)\n",
    "print posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method gives the highest likelihood of each state for each consecutive year during the 24 years span. We extract the highest probability each year to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.    35.75  36.    36.25  36.5   37.    37.25  37.5   37.75  38.25  38.\n",
      "  37.5   37.25  37.    36.5   36.25  35.75  35.5   35.    34.75  34.25  34.\n",
      "  33.5   33.25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.73149557,  0.67172685,  0.49284679,  0.59382251,\n",
       "        0.55075334,  0.7469954 ,  0.67981443,  0.70055597,  0.64082353,\n",
       "        0.59838834,  0.57080342,  0.70108201,  0.57178245,  0.59120162,\n",
       "        0.56611169,  0.85947428,  0.9178125 ,  0.95184709,  0.95589705,\n",
       "        0.94855793,  0.91926123,  0.79621273,  0.34756102])"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=np.zeros(len(posterior))\n",
    "prob=np.zeros(len(posterior))\n",
    "\n",
    "for i in range(len(posterior)):\n",
    "    year=posterior[i]\n",
    "    if i==0:\n",
    "        results[i]=0\n",
    "    else:\n",
    "        tresh=0\n",
    "        state=0\n",
    "        for st in discrete_states:\n",
    "            if year[st]>tresh:\n",
    "                tresh=year[st]\n",
    "                state=st\n",
    "        results[i]=state\n",
    "        prob[i]=tresh\n",
    "        \n",
    "print results\n",
    "prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1122dedd0>"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAGJCAYAAACJlEolAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhE/f8avtB85+VE6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10efa8590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(years,results,label=\"Estimation\")\n",
    "plt.plot(years,actual_deer,label=\"Actual\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Number of dears in Millions\")\n",
    "plt.title(\"Forward Backward algorithm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compare later with built in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "\n",
    "kf = KalmanFilter(transition_matrices = [[1, 1], [0, 1]], observation_matrices = [[0.1, 0.5], [-0.3, 0.0]])\n",
    "measurements = np.asarray([[1,0], [0,0], [0,1]])  # 3 observations\n",
    "kf = kf.em(measurements, n_iter=5)\n",
    "(filtered_state_means, filtered_state_covariances) = kf.filter(measurements)\n",
    "(smoothed_state_means, smoothed_state_covariances) = kf.smooth(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kf_predict(X, P, A, Q, B, U):\n",
    "    X = np.dot(A, X) + np.dot(B, U)\n",
    "    P = np.dot(A, np.dot(P, A.T)) + Q\n",
    "    return(X,P)\n",
    " \n",
    "def gauss_pdf(X, M, S):\n",
    "    if np.shape(M)[1] == 1:\n",
    "        DX=X - np.tile(M, np.shape(X)[1])\n",
    "        E=0.5 * np.sum(DX * (np.dot(inv(S), DX)), axis=0)\n",
    "        E=E + 0.5 * np.shape(M)[0] * np.log(2 * np.pi) + 0.5 * np.log(det(S))\n",
    "        P=np.exp(-E)\n",
    "    elif np.shape(X)[1] == 1:\n",
    "        DX=np.tile(X, np.shape(M)[1])- M\n",
    "        E=0.5 * np.sum(DX * (np.dot(inv(S), DX)), axis=0)\n",
    "        E=E + 0.5 * np.shape(M)[0] * np.log(2 * np.pi) + 0.5 * np.log(det(S))\n",
    "        P=np.exp(-E)\n",
    "    else:\n",
    "        DX=X-M\n",
    "        E=0.5 * np.dot(DX.T, np.dot(inv(S), DX))\n",
    "        E=E + 0.5 * np.shape(M)[0] * np.log(2 * np.pi) + 0.5 * np.log(det(S))\n",
    "        P=np.exp(-E)\n",
    "        \n",
    "    return (P[0],E[0]) \n",
    "\n",
    "def kf_update(X, P, Y, H, R):\n",
    "    IM=np.dot(H, X)\n",
    "    IS=R + np.dot(H, np.dot(P, H.T))\n",
    "    K=np.dot(P, np.dot(H.T, inv(IS)))\n",
    "    X=X + np.dot(K, (Y-IM))\n",
    "    P=P-np.dot(K, np.dot(IS, K.T))\n",
    "    LH=gauss_pdf(Y, IM, IS)\n",
    "    return (X,P,K,IM,IS,LH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =([[0.0], [0.0], [0.1], [0.1]])\n",
    "np.shape(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (41,9) and (41,1) not aligned: 9 (dim 1) != 41 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-584-138b62eba163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Applying the Kalman Filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkf_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkf_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m    \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-558-96eec2b67e67>\u001b[0m in \u001b[0;36mkf_predict\u001b[0;34m(X, P, A, Q, B, U)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkf_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (41,9) and (41,1) not aligned: 9 (dim 1) != 41 (dim 0)"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import *\n",
    "from numpy.linalg import inv \n",
    "#time step of observations\n",
    "dt = 1\n",
    "# Initialization of state matrices\n",
    "X = np.array(np.zeros((41,1)))\n",
    "X[0]=actual_deer[0]\n",
    "P = np.diag(np.zeros(41)*0.1)\n",
    "A = transition_f\n",
    "Q = np.eye(np.shape(X)[0])\n",
    "B = emission_f\n",
    "U = np.zeros((np.shape(X)[0],1)) \n",
    " \n",
    "    \n",
    "# Measurement matrices\n",
    "Y = np.array([[X[0,0] + abs(np.random.randn(1)[0])], [X[1,0] + abs(np.random.randn(1)[0])]])\n",
    "H = np.diag(np.zeros(41)*1)\n",
    "R = np.eye(np.shape(Y)[0])\n",
    "# Number of iterations in Kalman Filter\n",
    "N_iter = 50\n",
    "# Applying the Kalman Filter\n",
    "for i in np.arange(0, N_iter):\n",
    "    (X, P) = kf_predict(X, P, A, Q, B, U)\n",
    "    (X, P, K, IM, IS, LH) = kf_update(X, P, Y, H, R)\n",
    "    Y = np.array([[X[0,0] + abs(0.1 * np.random.randn(1)[0])],[X[1, 0] +\\\n",
    "    abs(0.1 * np.random.randn(1)[0])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialization of state matrices\n",
    "X = np.array([[0.0], [0.0], [0.1], [0.1]])\n",
    "P = np.diag((0.01, 0.01, 0.01, 0.01))\n",
    "A = np.array([[1, 0, dt , 0], [0, 1, 0, dt], [0, 0, 1, 0], [0, 0, 0,1]])\n",
    "Q = np.eye(np.shape(X)[0])\n",
    "B = np.eye(np.shape(X)[0])\n",
    "U = np.zeros((np.shape(X)[0],1)) \n",
    " \n",
    "Y = np.array([[X[0,0] + abs(np.random.randn(1)[0])], [X[1,0] + abs(np.random.randn(1)[0])]])\n",
    "H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]])\n",
    "R = np.eye(np.shape(Y)[0])\n",
    "\n",
    "# Number of iterations in Kalman Filter\n",
    "N_iter = 50\n",
    "# Applying the Kalman Filter\n",
    "for i in np.arange(0, N_iter):\n",
    "    (X, P) = kf_predict(X, P, A, Q, B, U)\n",
    "    (X, P, K, IM, IS, LH) = kf_update(X, P, Y, H, R)\n",
    "    Y = np.array([[X[0,0] + abs(0.1 * np.random.randn(1)[0])],[X[1, 0] +\\\n",
    "    abs(0.1 * np.random.randn(1)[0])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "\n",
    "Q = 1e-5 # process variance\n",
    "\n",
    "n_iter=50\n",
    "\n",
    "# intial parameters\n",
    "sz=50\n",
    "\n",
    "xhat=numpy.zeros(sz)      # a posteri estimate of x\n",
    "P=numpy.zeros(sz)         # a posteri error estimate\n",
    "xhatminus=numpy.zeros(sz) # a priori estimate of x\n",
    "Pminus=numpy.zeros(sz)    # a priori error estimate\n",
    "K=numpy.zeros(sz)         # gain or blending factor\n",
    "\n",
    "R = 0.1**2 # estimate of measurement variance, change to see effect\n",
    "\n",
    "# intial guesses\n",
    "xhat[0] = 0.0\n",
    "P[0] = 1.0\n",
    "\n",
    "for k in range(1,sz):\n",
    "    # time update\n",
    "    xhatminus[k] = xhat[k-1]\n",
    "    Pminus[k] = P[k-1]+Q\n",
    "\n",
    "    # measurement update\n",
    "    K[k] = Pminus[k]/( Pminus[k]+R )\n",
    "    xhat[k] = xhatminus[k]+K[k]*(z[k]-xhatminus[k])\n",
    "    P[k] = (1-K[k])*Pminus[k]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
